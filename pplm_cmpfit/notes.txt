=======================================================
Parallel Processing Legacy Levenberg Marquardt Routines
=======================================================

At the 2009 Astromed conference, one speaker commented that in his field, there was a decline of utilising traditional numerical non linear solvers as swarm optimization methods are inherently parallisable and GPUs were now a relatively cheap option. It is a truth that the traditional methods were developed at a time when parallisation was not a practical consideration and while new numerical code can be designed to exploit possible parallisation facilites, the well trusted legacy code generally cannot without major rewrites.

Recently, I was working on a project for the European Southern Observatory which required non linear fitting to a computationally expensive object function which was using mpfit, a C conversion of the MINPACK LMDIFF (Leveberg Marquardt using forward DIFFerence method to calculate derivatives) an algorithm that I am very familiar with. It ocurred to me that with regards the LMDIFF methods there is indeed one stage that can be parallel processed with minimal to no major rewrites as I shall explain.

Levenberg Marquardt methods require evaluations of the object function and all it's derivatives at specific values of the governing parameters. LMDERIV methods require that the user supply a function that performs all of these evaluation. LMDIFF methods only require that the user supply a function that calculates the object function only and the derivatives are numerically calculated using the forward difference method within a for loop iterating each parameter. The forward diffecerence calculation for any parameter requires the evaluation of the object function with an added small step to the parameter of interest. I realised that this is a for loop that can be exploited as an "OMP parallel for loop", which would then evaluate the object function calls for each parameter change in parallel. For each Levenberg Marquardt iteration, it is required to call the object function once for the values of interest and then n times for each derivative calculation. Thus in principle, given enough cores, the suggested parallisation process could result of a speed up by a factor (n+1)/2 where n is the number of parameters being fitted.

To test this idea, I modified the for loop in question in mpfit.c and tested on the simple 4 parameter guassfit test that comes with the cmpfit 1.4 package and did indeed derive a speedup of roughly 2 (for n=4, (n+1)/2=2.5). However, I did have to make several changes to the routine in question in order to satisfy the openmp requirements (i.e. replace the goto statements) and to ensure that there were no collisions with shared variables. While effective, I did dislike the need for such changes to third party code. Once such modifications are made, the onus of maintanence is on whoever made the modification. I am generally paid to provide solutions not to support third party software. Thus, I considered another option. If we used the LMDERIV method, then we would supply the routine that calculates the derivatives and that could have the openmp for loop. Despite being based on LMDIFF, mpfit does have the options to have the user function supply the derivative calculations, so I tested this strategy with unmodified mpfit and got similar results. There was one major disadvantage, however, and that was that in this mode the user supplied function is called twice at each iteration, once to return the value of the function for a set of parameter values and then again to return the derivative calculations for those set of parameter values. The latter needs the result values of the former. Thus an unfortunate consequence is that the function value for the same set of parameters were being evaluated twice. The simplest fix to this caveat is to store the last set of input and output values from the previous call, which while simple enough does require additional bookkeeping. As a final solution, I derived an add on package, pplm_mpfit, which provides a wrapper to mpfit calling a private function that will place the user specified function call into the required OMP for loop. By building this with the main code, all calls to mpfit(...) could be replaced with calls to pplm_mpfit(...). Thus, parallisation support without the need to modify directly the cmpfit package.
